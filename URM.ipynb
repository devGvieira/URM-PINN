{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN for Uniform Rectilinear Motion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.func import functional_call, grad, vmap\n",
    "import torchopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network's Architecture\n",
    "\n",
    "In the following cell, we define the archictecture's hyperparameters, note that the activation function applied here is a hyperbolic tangent (Tanh) for it being non-linear and ranging from -1 to 1. It is also interesting to pay attention to the fact that we are building the linear neural network from scratch due the lack of a PyTorch module specific for it, i.e., we are building a custom module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNN(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_inputs: int=1,\n",
    "            num_layers: int=1,\n",
    "            num_neurons: int=5,\n",
    "            act: nn.Module = nn.Tanh()\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_neurons = num_neurons\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # Input layer\n",
    "        layers.append(nn.Linear(self.num_inputs, num_neurons))\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers):\n",
    "            layers.extend([nn.Linear(num_neurons, num_neurons), act])\n",
    "\n",
    "        # Output layers\n",
    "        layers.append(nn.Linear(num_neurons, 1))\n",
    "\n",
    "        # Building the network as sequential\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    # Setting up the output\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.network(x.reshape(-1,1)).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Loss Function\n",
    "\n",
    "Below a Python function is developed to facilitate the development of our mathematical function, which afterwards will be used to define the network's loss function.   \n",
    "\n",
    "Given we are dealing with a Uniform Rectilinear Motion (URM), the differential equation is given by:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\dfrac{ds}{dt} - v = 0,\n",
    "\\end{equation}\n",
    "\n",
    "where $s$ refers to a temporal function of space, $t$ to time and $v$ to a constant velocity. Basically, this equation describes the movement of a body with constant velocity.\n",
    "\n",
    "In order to make it easier to generalize our model, the equation above will be rewritten as:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\dfrac{df}{dx} - c = 0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the structure created\n",
    "model = LinearNN()\n",
    "\n",
    "# Python function to build mathematical functions\n",
    "def f(x: torch.Tensor, params: dict[str, torch.nn.Parameter]) -> torch.Tensor:\n",
    "    return functional_call(model, params, (x, ))\n",
    "\n",
    "# Mathematical function\n",
    "dsdx = vmap(grad(f), in_dims=(0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the boundaries values\n",
    "## Space boundary\n",
    "S_BOUNDARY = 0.0\n",
    "## Velocity boundary\n",
    "C_BOUNDARY = 0.5\n",
    "\n",
    "def loss_fn(params: torch.Tensor, x: torch.Tensor):\n",
    "\n",
    "    # Interior equation\n",
    "    interior = dsdx(x, params) - C_BOUNDARY\n",
    "    \n",
    "    # Parametrizing boundary\n",
    "    s_boundary = torch.Tensor([S_BOUNDARY])\n",
    "    c_boundary = torch.Tensor([C_BOUNDARY])\n",
    "    \n",
    "    # Boundary equation\n",
    "    boundary = f(s_boundary, params) - c_boundary \n",
    "\n",
    "    # Setting Mean Squared Error as metric for loss\n",
    "    loss = nn.MSELoss()\n",
    "    # Getting numerical value for loss\n",
    "    loss_value = loss(interior, torch.zeros_like(interior)) + loss(boundary, torch.zeros_like(boundary))\n",
    "\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected all elements of parameter_and_buffer_dicts to be dictionaries",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iter):\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(batch_size)\u001b[38;5;241m.\u001b[39muniform_(domain[\u001b[38;5;241m0\u001b[39m], domain[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     params \u001b[38;5;241m=\u001b[39m optmizer\u001b[38;5;241m.\u001b[39msetp(loss, params)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mfloat\u001b[39m(loss)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m, in \u001b[0;36mloss_fn\u001b[0;34m(params, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_fn\u001b[39m(params: torch\u001b[38;5;241m.\u001b[39mTensor, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Interior equation\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     interior \u001b[38;5;241m=\u001b[39m \u001b[43mdsdx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m C_BOUNDARY\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Parametrizing boundary\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     s_boundary \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([S_BOUNDARY])\n",
      "File \u001b[0;32m~/Documents/URM-PINN/URM-venv/lib/python3.11/site-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/URM-PINN/URM-venv/lib/python3.11/site-packages/torch/_functorch/vmap.py:266\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    263\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/URM-PINN/URM-venv/lib/python3.11/site-packages/torch/_functorch/vmap.py:38\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/URM-PINN/URM-venv/lib/python3.11/site-packages/torch/_functorch/vmap.py:379\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 379\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/URM-PINN/URM-venv/lib/python3.11/site-packages/torch/_functorch/apis.py:363\u001b[0m, in \u001b[0;36mgrad.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meager_transforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/URM-PINN/URM-venv/lib/python3.11/site-packages/torch/_functorch/eager_transforms.py:1287\u001b[0m, in \u001b[0;36mgrad_impl\u001b[0;34m(func, argnums, has_aux, args, kwargs)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_impl\u001b[39m(func: Callable, argnums: argnums_t, has_aux: \u001b[38;5;28mbool\u001b[39m, args, kwargs):\n\u001b[1;32m   1286\u001b[0m     func \u001b[38;5;241m=\u001b[39m lazy_dynamo_disable(func)\n\u001b[0;32m-> 1287\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_and_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_aux\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1289\u001b[0m         grad, (_, aux) \u001b[38;5;241m=\u001b[39m results\n",
      "File \u001b[0;32m~/Documents/URM-PINN/URM-venv/lib/python3.11/site-packages/torch/_functorch/vmap.py:38\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/URM-PINN/URM-venv/lib/python3.11/site-packages/torch/_functorch/eager_transforms.py:1248\u001b[0m, in \u001b[0;36mgrad_and_value.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1245\u001b[0m diff_args \u001b[38;5;241m=\u001b[39m _slice_argnums(args, argnums, as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1246\u001b[0m tree_map_(partial(_create_differentiable, level\u001b[38;5;241m=\u001b[39mlevel), diff_args)\n\u001b[0;32m-> 1248\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/URM-PINN/URM-venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:328\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m dynamic_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     set_eval_frame(prior)\n",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m, in \u001b[0;36mf\u001b[0;34m(x, params)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(x: torch\u001b[38;5;241m.\u001b[39mTensor, params: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/URM-PINN/URM-venv/lib/python3.11/site-packages/torch/_functorch/functional_call.py:125\u001b[0m, in \u001b[0;36mfunctional_call\u001b[0;34m(module, parameter_and_buffer_dicts, args, kwargs, tie_weights, strict)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parameter_and_buffer_dicts, Sequence):\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(d, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m parameter_and_buffer_dicts):\n\u001b[0;32m--> 125\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    126\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all elements of parameter_and_buffer_dicts to be dictionaries\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m         )\n\u001b[1;32m    128\u001b[0m     all_keys \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m parameter_and_buffer_dicts \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[1;32m    129\u001b[0m     repeated_keys \u001b[38;5;241m=\u001b[39m [key \u001b[38;5;28;01mfor\u001b[39;00m key, n \u001b[38;5;129;01min\u001b[39;00m Counter(all_keys)\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Expected all elements of parameter_and_buffer_dicts to be dictionaries"
     ]
    }
   ],
   "source": [
    "batch_size = 30\n",
    "num_iter = 100\n",
    "learning_rate = 1e-1\n",
    "domain = (-5.0,5.0)\n",
    "\n",
    "optmizer = torchopt.FuncOptimizer(torchopt.adam(lr=learning_rate))\n",
    "\n",
    "params = tuple(model.parameters())\n",
    "\n",
    "for i in range(num_iter):\n",
    "\n",
    "    x = torch.FloatTensor(batch_size).uniform_(domain[0], domain[1])\n",
    "\n",
    "    loss = loss_fn(params, x)\n",
    "\n",
    "    params = optmizer.setp(loss, params)\n",
    "\n",
    "    print(f\"Iteration {i} with loss {float(loss)}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UARM-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
